{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0u35EADX7dpUfTMrnvUAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ze-2000/Processamento-de-Linguagem-Natural/blob/main/Processamento_de_Linguagem_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ubirajara ‚Äì Lenda Tupi, de Jos√© de Alencar"
      ],
      "metadata": {
        "id": "Axezv8mqVDFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo a Passo Detalhado ‚Äì An√°lise de Texto com Python (Google Colab)\n",
        "Este guia te ajudar√° a analisar o conte√∫do textual de Ubirajara usando t√©cnicas b√°sicas de Processamento de Linguagem Natural (PLN) em Python."
      ],
      "metadata": {
        "id": "re7BP5Y5VCXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 1 ‚Äì Leitura do Arquivo\n",
        "Objetivo: Carregar o conte√∫do do livro de um arquivo .txt."
      ],
      "metadata": {
        "id": "2rPzVVExVHNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ler_arquivo(caminho):\n",
        "    try:\n",
        "        with open(caminho, 'r', encoding='utf-8') as arquivo:\n",
        "            return arquivo.read()\n",
        "    except FileNotFoundError:\n",
        "        print(\"Arquivo n√£o encontrado.\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "vHzbwZbzVJdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∏ Exemplo de uso:"
      ],
      "metadata": {
        "id": "d1rzERL1VK1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hNu8d8c7VVw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = ler_arquivo(\"Ubirajara.txt\")\n",
        "print(texto[:1000])  # Exibe os primeiros 1000 caracteres\n"
      ],
      "metadata": {
        "id": "UAtY0vWUVN1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Etapa 2 ‚Äì Buscador de Palavras com Contexto\n",
        "Objetivo: Buscar uma palavra no texto, exibindo um trecho ao redor como contexto."
      ],
      "metadata": {
        "id": "lwwhWNUWVOh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_palavra(texto, palavra, contexto=40):\n",
        "    texto_lower = texto.lower()\n",
        "    palavra_lower = palavra.lower()\n",
        "    ocorrencias = []\n",
        "    pos = texto_lower.find(palavra_lower)\n",
        "    while pos != -1:\n",
        "        inicio = max(0, pos - contexto)\n",
        "        fim = pos + len(palavra_lower) + contexto\n",
        "        trecho = texto[inicio:fim]\n",
        "        ocorrencias.append(trecho)\n",
        "        pos = texto_lower.find(palavra_lower, pos + 1)\n",
        "    print(\"Total de ocorr√™ncias:\", len(ocorrencias))\n",
        "    return ocorrencias\n"
      ],
      "metadata": {
        "id": "EcilhIYsVQjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∏ Exemplo de uso:"
      ],
      "metadata": {
        "id": "oBG4-GZiVWqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trechos = buscar_palavra(texto, \"guerreiro\")\n",
        "for trecho in trechos[:5]:\n",
        "    print(\"...\", trecho, \"...\\n\")\n"
      ],
      "metadata": {
        "id": "20UV2n8-VS41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 3 ‚Äì Limpeza e Pr√©-processamento do Texto\n",
        "Objetivo: Normalizar o texto e remover pontua√ß√µes, n√∫meros e stopwords (palavras comuns como ‚Äúde‚Äù, ‚Äúa‚Äù, ‚Äúe‚Äù)."
      ],
      "metadata": {
        "id": "XVq-k1FhV6kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def limpar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)  # Remove pontua√ß√µes\n",
        "    palavras = texto.split()\n",
        "    palavras = [p for p in palavras if p.isalpha()]  # Remove n√∫meros\n",
        "    palavras = [p for p in palavras if p not in stopwords.words('portuguese')]  # Remove stopwords\n",
        "    return palavras\n"
      ],
      "metadata": {
        "id": "ZQWfscDaV8P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∏ Exemplo de uso:"
      ],
      "metadata": {
        "id": "kEzn56W1WCYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_limpo = limpar_texto(texto)\n",
        "print(palavras_limpo[:20])\n"
      ],
      "metadata": {
        "id": "xqrE7wIJWF9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 4 ‚Äì An√°lise de Frequ√™ncia de Palavras\n",
        "Objetivo: Contar as palavras mais frequentes no texto processado."
      ],
      "metadata": {
        "id": "UNo122EWWIGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def frequencia_palavras(lista_palavras, top_n=20):\n",
        "    contador = Counter(lista_palavras)\n",
        "    return contador.most_common(top_n)\n"
      ],
      "metadata": {
        "id": "PHQpfQRUWKiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∏ Exemplo de uso:"
      ],
      "metadata": {
        "id": "OlNpVSrjWc3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mais_frequentes = frequencia_palavras(palavras_limpo)\n",
        "for palavra, freq in mais_frequentes:\n",
        "    print(f\"{palavra}: {freq}\")\n"
      ],
      "metadata": {
        "id": "dDViNZ_oWYAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualiza√ß√£o Gr√°fica\n",
        "Objetivo: Visualizar as palavras mais frequentes com um gr√°fico de barras.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JO73cQl0Wgvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotar_frequencia(palavras_freq):\n",
        "    palavras, frequencias = zip(*palavras_freq)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.bar(palavras, frequencias, color='skyblue')\n",
        "    plt.title(\"Palavras mais frequentes\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "p6IarrhXWi39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî∏ Exemplo de uso:"
      ],
      "metadata": {
        "id": "XqX-U4_mW_k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotar_frequencia(mais_frequentes)\n"
      ],
      "metadata": {
        "id": "LxOBtMBJXDze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}