# Processamento-de-Linguagem-Natural

 Ubirajara â€“ Lenda Tupi, de JosÃ© de Alencar
Nota: O conteÃºdo completo do livro foi extraÃ­do do Projeto Gutenberg e estÃ¡ em domÃ­nio pÃºblico. Como ele Ã© extenso, para facilitar, vocÃª pode colar apenas trechos relevantes no seu cÃ³digo Python, ou carregar o arquivo Ubirajara.txt no Google Colab.

ğŸ§ª Passo a Passo Detalhado â€“ AnÃ¡lise de Texto com Python (Google Colab)
Este guia te ajudarÃ¡ a analisar o conteÃºdo textual de Ubirajara usando tÃ©cnicas bÃ¡sicas de Processamento de Linguagem Natural (PLN) em Python.

âœ… Etapa 1 â€“ Leitura do Arquivo
Objetivo: Carregar o conteÃºdo do livro de um arquivo .txt.

python
Copiar
Editar
def ler_arquivo(caminho):
    try:
        with open(caminho, 'r', encoding='utf-8') as arquivo:
            return arquivo.read()
    except FileNotFoundError:
        print("Arquivo nÃ£o encontrado.")
        return ""
ğŸ”¸ Exemplo de uso:

python
Copiar
Editar
texto = ler_arquivo("Ubirajara.txt")
print(texto[:1000])  # Exibe os primeiros 1000 caracteres
ğŸ” Etapa 2 â€“ Buscador de Palavras com Contexto
Objetivo: Buscar uma palavra no texto, exibindo um trecho ao redor como contexto.

python
Copiar
Editar
def buscar_palavra(texto, palavra, contexto=40):
    texto_lower = texto.lower()
    palavra_lower = palavra.lower()
    ocorrencias = []
    pos = texto_lower.find(palavra_lower)
    while pos != -1:
        inicio = max(0, pos - contexto)
        fim = pos + len(palavra_lower) + contexto
        trecho = texto[inicio:fim]
        ocorrencias.append(trecho)
        pos = texto_lower.find(palavra_lower, pos + 1)
    print("Total de ocorrÃªncias:", len(ocorrencias))
    return ocorrencias
ğŸ”¸ Exemplo:

python
Copiar
Editar
trechos = buscar_palavra(texto, "guerreiro")
for trecho in trechos[:5]:
    print("...", trecho, "...\n")
ğŸ§¹ Etapa 3 â€“ Limpeza e PrÃ©-processamento do Texto
Objetivo: Normalizar o texto e remover pontuaÃ§Ãµes, nÃºmeros e stopwords (palavras comuns como â€œdeâ€, â€œaâ€, â€œeâ€).

python
Copiar
Editar
import re
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

def limpar_texto(texto):
    texto = texto.lower()
    texto = re.sub(r'[^\w\s]', '', texto)  # Remove pontuaÃ§Ãµes
    palavras = texto.split()
    palavras = [p for p in palavras if p.isalpha()]  # Remove nÃºmeros
    palavras = [p for p in palavras if p not in stopwords.words('portuguese')]  # Remove stopwords
    return palavras
ğŸ”¸ Exemplo:

python
Copiar
Editar
palavras_limpo = limpar_texto(texto)
print(palavras_limpo[:20])
ğŸ“Š Etapa 4 â€“ AnÃ¡lise de FrequÃªncia de Palavras
Objetivo: Contar as palavras mais frequentes no texto processado.

python
Copiar
Editar
from collections import Counter

def frequencia_palavras(lista_palavras, top_n=20):
    contador = Counter(lista_palavras)
    return contador.most_common(top_n)
ğŸ”¸ Exemplo:

python
Copiar
Editar
mais_frequentes = frequencia_palavras(palavras_limpo)
for palavra, freq in mais_frequentes:
    print(f"{palavra}: {freq}")
ğŸ“ˆ Etapa Extra â€“ VisualizaÃ§Ã£o GrÃ¡fica (opcional)
Objetivo: Visualizar as palavras mais frequentes com um grÃ¡fico de barras.

python
Copiar
Editar
import matplotlib.pyplot as plt

def plotar_frequencia(palavras_freq):
    palavras, frequencias = zip(*palavras_freq)
    plt.figure(figsize=(10,6))
    plt.bar(palavras, frequencias, color='skyblue')
    plt.title("Palavras mais frequentes")
    plt.xticks(rotation=45)
    plt.show()
ğŸ”¸ Exemplo:

python
Copiar
Editar
plotar_frequencia(mais_frequentes)
